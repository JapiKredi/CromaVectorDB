# CromaVectorDB

Having a smart and efficient way to handle data is crucial. 
Here, we explore the capabilities of ChromaDB, an open-source vector embedding database that allows users to perform semantic search. 
ChromaDB stores documents as dense vector embeddings, which are typically generated by transformer-based language models, allowing for nuanced semantic retrieval of documents. 
In this GitHub blog post, we will demonstrate how to create and store embeddings in ChromaDB and retrieve semantically matching documents based on user queries.

ChromaDB is a powerful tool that allows us to handle and search through data in a semantically meaningful way. 
It provides flexibility in terms of the transformer models used to create embeddings and offers efficient ways to narrow down search results. 
Whether you're managing a small collection of documents or a large database, ChromaDB's ability to handle semantic search can help you find the most relevant information quickly and accurately.

1: We start off by installing the required packages.
2: For our demonstration, we use a set of rtf files stored in a folder named "pets". Each file contains information about a different aspect of pet care.
3: Next, we need to connect to ChromaDB and create a collection. By default, ChromaDB uses the Sentence Transformers all-MiniLM-L6-v2 model to create embeddings.
4: We add some documents to our collection, along with corresponding metadata and unique IDs.
5: We can query our collection. Let's search for the term "vehicle". The returned result should be the document about the car.
6: Let's add our pet documents to the collection. We start by reading all the text files from the "pets" folder and storing the data in a list.
7: Adding File Contents to ChromaDB: we create separate lists for documents, metadata, and ids, which we add to our collection.
8: Performing Semantic Searches: Let's now query the collection for the different kinds of pets people commonly own.
9: Filtering Results: If we want to refine your search further, we can use the where_document parameter to specify a condition that must be met in the document text. 
10: Using a different model for embedding: While ChromaDB uses the Sentence Transformers all-MiniLM-L6-v2 model by default, you can use any other model for creating embeddings. In this example, we use the 'paraphrase-MiniLM-L3-v2' model from Sentence Transformers.
